<!DOCTYPE html>
<html lang='en'>
<head>
<meta charset='utf-8'>
<style>
 ul {
   margin: 0em;
   padding: 0em;
   display: flex;
   flex-wrap: wrap;
   flex-direction: row;
 }

 ul li {
   width: 40%;
   height: 9em;
   display: block;
   list-style: none;
   position: relative;
   padding-left: 5px;
   margin-left: 0em;
   margin-bottom: 5px;
 }

 ul li img {
   position: absolute;
   left: -7em;
   width: 7em;
   height:7em;
 }

 p {
  text-align: justify;
  text-justify: inter-word;
 }
</style>
</head>
<body>
<h1>Table of Contents</h1>
<h2>Session A</h2><ol>
<li><strong>Maciej Michalski, Patryk Ferenc, Sebastian Górka</strong>&nbsp;Session A<br/><a href="#6">Convolutional Kolmogorov Arnold Networks as an accurate alternative to Convolutional Neural Networks for rule discovery in Game of Life</a></li>
<li><strong>Piotr Klepacki</strong>&nbsp;Session A<br/><a href="#11">Mamba SSM with Kalman Filtering in Pendulum RL environment</a></li>
<li><strong>Michał Kostera, Paweł Cegielski</strong>&nbsp;Session A<br/><a href="#24">Procedural civilization development including economical aspects and the terrain.</a></li>
<li><strong>Jan Konarski</strong>&nbsp;Session A<br/><a href="#38">Optimization of neural network model for malware detection accelerated on mobile NPUs</a></li>
<li><strong>Grzegorz Zając, Mikolaj Stasiak, Wiktor Ważny</strong>&nbsp;Session A<br/><a href="#54">Line Follower Algorithm for a Flying Quadcopter</a></li>
</ol><h2>Session B</h2><ul>
<li><strong>Ignacy Ruszpel, Nikodem Wójcik</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;1<br/><a href="#2">Accelerating AI Inference in the Browser with WebGPU: Evaluating Quantization Trade-offs in Latency, Quality, and Memory Usage</a></li>
<li><strong>Jakub Romanek, Marcin Latawiec</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;2<br/><a href="#10">Enhancing Phishing Detection on Websites: A Hybrid Approach Combining Signature-Based Detection and Traditional Machine Learning Methods - Abstract</a></li>
<li><strong>Mikołaj Klębowski</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;3<br/><a href="#14">Przewidywanie wstrząsów wtórnych przy pomocy Sieci Neuronowych.</a></li>
<li><strong>Jan Kruszyński, Karim Sonbul, Magdalena Markowicz, Piotr Podgórski</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;4<br/><a href="#15">Explainability of Convolutional Neural Network: Overview of Methods</a></li>
<li><strong>Michal Wójtowicz, Michał Biliński</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;5<br/><a href="#16">Evaluating detection methods of synthetic images</a></li>
<li><strong>Piotr Wróbel</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;6<br/><a href="#17">Comparative Analysis of Multi-Agent LLM Systems for Solving Polish Matura in Physics Exams</a></li>
<li><strong>Bartosz Staszynski, Filip Karpowicz, Wiktor Kępiński</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;7<br/><a href="#19">Examination of PCA Utilisation for Multilabel Classifier of Multispectral Images</a></li>
<li><strong>Dominika Pacek, Nina Łabęcka</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;8<br/><a href="#20">Post-Quantum Cryptography: Benchmarking ML-KEM Against RSA</a></li>
<li><strong>Jakub Jasiński</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;9<br/><a href="#21">Analysis and comparison of missing value imputation methods for atmospheric pollution data</a></li>
<li><strong>Jakub Karpiński</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;10<br/><a href="#23">Comparative Analysis of Machine Learning and Statistical Models for Short-Term Energy Production Forecasting in Poland</a></li>
<li><strong>Tomasz Gryczka</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;11<br/><a href="#26">Verification of the authenticity of bullion coins with a mobile application based on frequency analysis using an artificial neural network</a></li>
<li><strong>Marcin Dydo</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;12<br/><a href="#29">Evaluating unsupervised data mining methods to assess the utility of such approaches for SIEM event analysis.</a></li>
<li><strong>Oskar Wyłucki</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;13<br/><a href="#30">Comparing the Efficiency of Selected Reinforcement Learning Algorithms in Stability Control and Navigation Tasks</a></li>
<li><strong>Daniel Kisiel, Eryk Muchorowski</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;14<br/><a href="#31">A Lung Volume-Based Perfusion SPECT and CT Comparison Algorithm for Enhanced Pulmonary Embolism Diagnosis</a></li>
<li><strong>Jakub Urbański</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;15<br/><a href="#34">Comparison of Models for Automatic Description of Medical Images</a></li>
<li><strong>Małgorzata Sokół</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;16<br/><a href="#35">Zastosowanie modeli GAN do usuwania artefaktów z sygnału EEG</a></li>
<li><strong>Marcin Łomiński, Michał Tomczyk</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;17<br/><a href="#39">Exploring LLMs mathematical reasoning capability: Insights from GSM-Symbolic in English and Polish</a></li>
<li><strong>Mateusz Bartosik, Mikolaj Zawada</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;18<br/><a href="#40">Franky: An Intelligent Agent for Stock Portfolio Management Using Large Language Models and Deep Reinforcement Learning</a></li>
<li><strong>Tomasz Nitsch</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;19<br/><a href="#41">Automatic translation of Japanese manga using MultiModal Large Language Models</a></li>
<li><strong>Barbara Borkowska, Marcin Maciąg</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;20<br/><a href="#42">Proxy Methods in Image Recognition</a></li>
<li><strong>Daniel Kuciński, Tomasz Mycielski</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;21<br/><a href="#45">Optimizing Football Betting Strategies Using Deep Neural Networks and Modern Portfolio Theory</a></li>
<li><strong>Kacper Gorlowski</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;22<br/><a href="#47">Testy penetracyjne systemu zarządzania energią elektryczną OpenEMS — identyfikacja i mitygacja podatności w otwartoźródłowych systemach energetycznych</a></li>
<li><strong>Marcel Mikołajczyk</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;23<br/><a href="#48">Enhancing Large Language Models with Retrieval-Augmented Generation: A Case Study on Movie Data Beyond the Training Cutoff</a></li>
<li><strong>Oskar Rozwadowski</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;24<br/><a href="#50">Ethereum price forecasting using deep neural networks</a></li>
<li><strong>Wojciech Jakieła</strong>&nbsp;Session&nbsp;B&nbsp;/&nbsp;Stand&nbsp;25<br/><a href="#51">Pose-Based Motion Analysis for Physical Exercise Quality Assessment</a></li>
</ul><h2>Session C</h2><ul>
<li><strong>Filip Horst</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;1<br/><a href="#1">Perception manipulation and subjective reception of data</a></li>
<li><strong>Bartosz Nowicki, Karol Kociołek, Wiktor Wołek</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;2<br/><a href="#3">BBot - Behavioral reinforced learning bot to play blood bowl</a></li>
<li><strong>Michał Ankiersztajn</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;3<br/><a href="#4">Comparison of multiplatform technologies for mobile application development</a></li>
<li><strong>Rafał Zan</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;4<br/><a href="#5">Attacks on LSTM-Based Recurrent Neural Networks for Sentiment Analysis</a></li>
<li><strong>Jerzy Balcer</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;5<br/><a href="#7">User experience laws: a literature review and practical examples based on DoorCE project</a></li>
<li><strong>Jakub Szczygielski, Michał Żdanuk</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;6<br/><a href="#8">Overview of Communication Mechanisms Adopted in Modern Systems</a></li>
<li><strong>Konrad Trusiewicz, Mikołaj Guryn, Zuzanna Gaik</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;7<br/><a href="#9">Development of a model of the electric field distribution inside the human brain</a></li>
<li><strong>Paweł Prokopiuk</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;8<br/><a href="#12">Comparative Analysis of Continuous Software Delivery Tools Using Github Actions and Jenkins as Examples</a></li>
<li><strong>Dawid Pura</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;9<br/><a href="#13">Wpływ stopnia sprzężenia klas na czas wprowadzenia zmian - badanie empiryczne</a></li>
<li><strong>Jakub Witczak</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;10<br/><a href="#18">Flutter vs. React for Web Applications: A Comparative Benchmark Study of Performance Metrics and Developer Experience</a></li>
<li><strong>Adam Sadowski, Dorota Szulc, Jakub Ćwiek, Jan Kowalik, Krzysztof Jęczmieniowski, Ryszard Kucharski</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;11<br/><a href="#22">Badania i Implementacja Innowacyjnego Systemu Zasobnika Energii Współpracującego z Odnawialnymi Źródłami Energii INNOSTOR dla Zrównoważonego Rozwoju na Politechnice Warszawskiej</a></li>
<li><strong>Maciej Majek</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;12<br/><a href="#25">Spatio-Temporal Memory System for Robots: Enabling Long-Term Contextual Reasoning</a></li>
<li><strong>Feliks Brzeziński, Kacper Olszewski, Patrycja Płodowska</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;13<br/><a href="#27">Projekt uniwersalnego robota modularnego</a></li>
<li><strong>Jakub Maciejewski, Michał Ziober</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;14<br/><a href="#28">HDR - the impact of input parameters on the result for Debevec algorithm</a></li>
<li><strong>Adam Pilewski, Mikołaj Kordowski</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;15<br/><a href="#33">Przegląd znakowania wodnego obrazów we współczesnych zastosowaniach</a></li>
<li><strong>Antoni Olszewski</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;16<br/><a href="#36">Blazor WebAssembly and React comparison</a></li>
<li><strong>Daniel Stańkowski, Daniel Ślusarczyk, Paweł Tęcza</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;17<br/><a href="#37">Machine Learning-Based Examination of ESG Factors in Stock Predictions</a></li>
<li><strong>Jan Guziuk, Hubert Masłowski</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;18<br/><a href="#43">Threat Detection in IIoT Networks through Deep Packet Inspection and Machine Learning Mechanisms</a></li>
<li><strong>Aleksy Bałaziński</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;19<br/><a href="#44">Selected methods in N-body simulations</a></li>
<li><strong>Jakub Ciszewski, Kaja Myk</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;20<br/><a href="#46">Performance Comparison of WebAssembly and  JavaScript</a></li>
<li><strong>Darya Vasilchyk</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;21<br/><a href="#49">Wpływ facylitacji na efektywność spotkań w projektach IT</a></li>
<li><strong>Hubert Kołcz</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;22<br/><a href="#52">Low-cost, home-made Quantum Computer</a></li>
<li><strong>Stanislaw Zań</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;23<br/><a href="#53">Database Index Costs in the Cloud-Based Multitenant Architecture on the Salesforce Platform</a></li>
<li><strong>Paweł Podgórski</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;24<br/><a href="#55">A Survey of Consensus Algorithms in Distributed Ledger Technology for Internet of Things</a></li>
<li><strong>Konrad Zilinski</strong>&nbsp;Session&nbsp;C&nbsp;/&nbsp;Stand&nbsp;25<br/><a href="#57">Comparison of the Performance and Effectiveness of Hashing Algorithms</a></li>
</ul>
<h1 id="6">Convolutional Kolmogorov Arnold Networks as an accurate alternative to Convolutional Neural Networks for rule discovery in Game of Life</h1><h3>Maciej Michalski, Patryk Ferenc, Sebastian Górka</h3><p>The interpretability of artificial neural networks (ANNs) remains a challenge, particularly as they grow deeper and incorporate millions of parameters. Kolmogorov-Arnold Networks (KANs) address this issue by using fewer parameters than traditional ANNs and representing functions as symbolic formulas, while maintaining comparable performance. John Conway's Game of Life (GoL) serves as an example of reverse-engineering the rules underlying simple natural processes. We trained several networks, including KANs, Convolutional KANs (CKANs), and traditional Convolutional Neural Networks (CNNs), on a dataset of GoL-generated images and compared the learned kernels with expected ones. Our findings show that both CKANs and CNNs can recover the rules of simple processes like GoL while validating model performance against traditional CNNs.</p>
<h1 id="11">Mamba SSM with Kalman Filtering in Pendulum RL environment</h1><h3>Piotr Klepacki</h3><p>State-space models (SSMs) have emerged as a compelling  alternative to Transformer architectures, delivering comparable  performance at significantly lower computational cost. Although deterministic SSMs such as Mamba have achieved  state-of-the-art results in areas like sequence modelling and  image segmentation, their deterministic nature limits their  suitability for probabilistic reinforcement learning (RL) environments, where uncertainty is intrinsic.  This paper introduces an architecture that integrates the  Mamba SSM with the Kalman filter, enabling it to learn and  adapt to uncertain environment dynamics. We validate the effectiveness of this approach on a modified Pendulum task from  the Gymnasium RL library, demonstrating its potential for  learning and representing complex dynamics in probabilistic  settings.</p>
<h1 id="24">Procedural civilization development including economical aspects and the terrain.</h1><h3>Michał Kostera, Paweł Cegielski</h3><p>This article presents the project's results, focused on the simulation of civilizations that develop over time. The development is primarily influenced by three main factors: the terrain on which the tribes are initially placed, available resources, and economic aspects, such as trading with one another. The world is generated using procedural techniques, which return a world with realistic terrain shape, temperature, wind and humidity. The tribes traverse the terrain in search of resources and a spot to settle down while also interacting with other tribes and taking different courses of action based on their behaviours and their history with each other. After settling down, the tribe begins to build a city, trying to provide housing and food to each of its members, becoming self-sufficient and creating a better environment for future growth. The cities are generated using procedural techniques, mainly L-systems, and develop over time, creating more advanced types of buildings (such as taverns and temples) while improving existing housing.</p>
<h1 id="38">Optimization of neural network model for malware detection accelerated on mobile NPUs</h1><h3>Jan Konarski</h3><p>With the increasing number of cyber threats, malware detection has become a critical challenge in cybersecurity. Traditional detection techniques, based on behavioral analysis and signature creation, present significant challenges due to their time-consuming nature and limited effectiveness against new, unknown threats. This paper explores the optimization of artificial intelligence (AI) for malware detection, leveraging acceleration on mobile neural processing units (NPUs). The primary goal of this study is to develop and evaluate methods that enhance machine learning models in terms of computational efficiency and detection accuracy in resource-constrained environments.  The research methodology involved designing the initial model on a high-performance computing system to determine the optimal network size that balances processing speed and detection precision across various devices. A more precise version of the model was subsequently trained on more powerful hardware, followed by the application of optimization techniques to adapt it for execution on mobile NPUs.  The study examines the performance of different NPU architectures and assesses the impact of operating systems on the efficiency and speed of AI-based detection models. Preliminary findings indicate that the applied optimizations have led to satisfactory results in detecting malicious code within binary files on Windows systems.  This research contributes to the development of AI deployment methods on mobile devices, which can significantly enhance end-user security without relying on external cloud-based solutions. Future studies aim to expand the analysis to software running on other platforms.</p>
<h1 id="54">Line Follower Algorithm for a Flying Quadcopter</h1><h3>Grzegorz Zając, Mikolaj Stasiak, Wiktor Ważny</h3><p>As interest in aerial drones and autonomous systems grows, so does the need for optimal solutions that can be run on minimalistic hardware. This paper describes an autonomous, vision-based algorithm designed for participation in the MathWorks Minidrone Competition. The algorithm was developed within competition’s specification and the authors won the 3rd place in the nationwide MathWorks Minidrone Competition Poland 2025. The work done included research on publicly available, already existing solutions as well as on tools that could be applied to the task at hand. As a result a custom vision algorithm was developed to balance fidelity and speed and to minimise the computing power required.  The drone software, written entirely in Matlab is capable of controlling a Parrot Mambo mini drone tasked with traversing a course made of red straight lines joined at different angles. The programme is designed around a built-in low-resolution camera pointing downwards. The work focuses on the design and development of an image processing algorithm as well as path planner and flight control programs that transform a low resolution image into a list of instructions for the drone.</p>
<h1 id="2">Accelerating AI Inference in the Browser with WebGPU: Evaluating Quantization Trade-offs in Latency, Quality, and Memory Usage</h1><h3>Ignacy Ruszpel, Nikodem Wójcik</h3><p>Recent advances in deep learning and natural language processing have spurred the demand for deploying increasingly complex models on resource-constrained platforms. Modern browser environments, empowered by emerging GPU standards like WebGPU, now offer a promising venue for real-time AI inference. This paper provides an overview of leveraging WebGPU for accelerating inference directly within the browser, with a focus on evaluating the trade-offs associated with various quantization schemes. Our study examines the impact of quantization on inference latency, model quality, and memory usage across several model variants. Preliminary benchmarks demonstrate that carefully applied quantization can substantially reduce resource demands while maintaining acceptable performance, laying the groundwork for further optimization of browser-based AI applications. This work sets the stage for future explorations aimed at refining quantization techniques and expanding the capabilities of WebGPU-driven inference.</p>
<h1 id="10">Enhancing Phishing Detection on Websites: A Hybrid Approach Combining Signature-Based Detection and Traditional Machine Learning Methods - Abstract</h1><h3>Jakub Romanek, Marcin Latawiec</h3><p>With the increasing popularity of web services and the significant amount of time users spend online, cybercriminals are increasingly targeting this space with sophisticated malicious techniques. Phishing, one of the most prevalent cybersecurity threats, poses a substantial risk to both individuals and organizations. These attacks are typically executed via deceptive emails containing fraudulent URLs that redirect users to malicious websites designed to steal sensitive information. The consequences of phishing can be severe, including financial loss, identity theft, and malware infections. To mitigate phishing threats, implementing an effective detection framework is essential. Existing detection techniques include signature-based methods, traditional machine learning models, and deep learning approaches. However, each method has inherent limitations, making it challenging to rely solely on a single technique. We propose a hybrid phishing detection approach that integrates signature-based detection with a machine learning model to enhance both versatility and robustness against phishing attacks. Email file in EML format works as an input to our solution which is later processed to extract hyperlinks from body of the message. Those URLs are then passed to signature-based detection component and machine learning model. The first component utilizes an API wrapper for the widely used cyber-threat intelligence platform. Meanwhile, the machine learning model is trained on feature extraction techniques using the open-source phishing URL dataset. Those features are based on URL attributes (e.g. domain length, HTTPS usage, number of special characters) and HTML attributes (e.g. number of hidden fields, redirections, JavaScript references). For the research purposes, we trained three different machine learning models: Decision Tree, MLP (Multi-Layer Perceptrons network), and SVM (Support Vector Machines). All of our models achieved an impressive accuracy of 0.9988, 0.9994, and 0.9982, respectively, demonstrating its effectiveness in identifying phishing threats. The results indicate that this hybrid approach can serve as a reliable cybersecurity tool, capable of detecting both existing and emerging phishing attacks with high precision.</p>
<h1 id="14">Przewidywanie wstrząsów wtórnych przy pomocy Sieci Neuronowych.</h1><h3>Mikołaj Klębowski</h3><p>Silne trzesienia ziemi niosą ze soba ryzyko wystapienia wstrzasów wtórnych, które moga powodować większe zniszczenia niż główne trzesienie. Ze wzgledu na złożoność tego zjawiska oraz gwałtowność jego przebiegu, prognozowanie czasu wystapienia i intensywności wstrzasów wtórnych stanowi wciąż istotne wyzwanie dla sejsmologii. W niniejszym artykule  zaprezentowano podejście do predykcji wstrzasów wtórnych na podstawie analizy sejsmogramów głównego zdarzenia. W tym celu zastosowano sieci konwolucyjne (CNN) oraz rekurencyjne (RNN) do budowy modeli predykcyjnych. Sieci konwolucyjne,  wyspecjalizowane w rozpoznawaniu wzorców, wykorzystano do identyfikacji trzesień ziemi, które moga wywołać wstrzasy  wtórne. Umożliwiaja one analizę zarówno w dziedzinie czasu – przy czym surowy sejsmogram stanowi bezpośrednie wejście  do sieci neuronowej – jak i w dziedzinie czestotliwości, gdzie  zastosowanie transformaty Fouriera pozwala uzyskać widmo sejsmogramu. Dodatkowo, sieci rekurencyjne zostały użyte do modelowania korelacji pomiedzy poszczególnymi segmentami czasowymi. Proponowana metodologia zakłada optymalizacje całego  systemu, majaca na celu zwiekszenie dokładności przewidywania zjawisk wtórnych przy jednoczesnym ograniczeniu liczby fałszywych alarmów. W dłuższej perspektywie rozwiazanie to może przyczynić sie do zwiekszenia bezpieczeństwa ludności oraz usprawnienia podejmowania decyzji dotyczacych organizacji akcji ratowniczych i planowania działań prewencyjnych. Dalszy rozwój przedstawionego podejścia planowany jest w kierunku zwiekszenia precyzji wykrywania słabszych zjawisk sejsmicznych</p>
<h1 id="15">Explainability of Convolutional Neural Network: Overview of Methods</h1><h3>Jan Kruszyński, Karim Sonbul, Magdalena Markowicz, Piotr Podgórski</h3><p>Understanding and interpreting the decisions made by deep learning models has become an essential area of research in artificial intelligence. Convolutional neural networks (CNNs), despite their high performance in various tasks, often function as "black boxes," making it challenging to explain their predictions. This study focuses on applying and evaluating different explainability techniques to CNN models to gain more insight into their decision-making processes. Using multiple approaches, our aim was to assess the effectiveness and reliability of these methods in improving the transparency and interpretability of neural networks.</p>
<h1 id="16">Evaluating detection methods of synthetic images</h1><h3>Michal Wójtowicz, Michał Biliński</h3><p>The paper aims to evaluate the effectiveness of available detectors in distinguishing fake from real photos. Deepfakes are artificially generated images or videos created using artificial intelligence or manual tools like Photoshop. New techniques, such as Generative Adversarial Networks (GANs) and Diffusion Models (DMs) enable the rapid generation of highly realistic images. The research utilizes the StyleGAN3 (GAN) and Stable Diffusion XL (DM) models, which were previously fine-tuned on photos of beaten people obtained from the Internet to generate new images. Tests of the detectors were carried out to assess the detector's precision, sensitivity, and resistance to manipulations, such as graphic filters or compression, as well as resistance to fingerprint removal tools. Older detectors that were not trained on the tested generative models struggle to detect fake photos. In contrast, newer detectors trained on new latest models achieve surprisingly good results. These results highlight the need for continuous updates to detection systems to counteract evolving deepfake generation techniques.</p>
<h1 id="17">Comparative Analysis of Multi-Agent LLM Systems for Solving Polish Matura in Physics Exams</h1><h3>Piotr Wróbel</h3><p>Large Language Models have gained widespread  recognition since OpenAI released their revolutionary model, ChatGPT 3.5. Since then, many new approaches have emerged  to improve the capabilities and accuracy of these models for  different tasks. One such method involves using multi-agent  conversations. This article compares two multi-agent setups  designed to solve the Polish standardized high school exam in  physics. Comparative benchmarks were performed on several  real final exams published by the Polish Central Examination  Board (pl. CKE — Centralna Komisja Egzaminacyjna). The  study employed ChatGPT-4 Turbo and the AutoGen framework.  Benchmarks covered a total of 90 tasks from three Polish Matura  physics exams (editions: 2018, 2019, 2023). The simpler multiagent systems achieved an average score of 76.1%, while the  more complex systems averaged 85.6%.</p>
<h1 id="19">Examination of PCA Utilisation for Multilabel Classifier of Multispectral Images</h1><h3>Bartosz Staszynski, Filip Karpowicz, Wiktor Kępiński</h3><p>This paper investigates the utility of Principal Component Analysis (PCA) for multi-label classification of multispectral images using ResNet50 and DINOv2, acknowledging the high dimensionality of such data and the associated processing challenges. Multi-label classification, where each image may belong to multiple classes, adds further complexity to feature extraction. Our pipeline includes an optional PCA step that reduces the data to three dimensions before feeding it into a three-layer classifier. The findings demonstrate that the effectiveness of PCA for multi-label multispectral image classification depends strongly on the chosen deep learning architecture and training strategy, opening avenues for future research into self-supervised pre-training and alternative dimensionality reduction approaches.</p>
<h1 id="20">Post-Quantum Cryptography: Benchmarking ML-KEM Against RSA</h1><h3>Dominika Pacek, Nina Łabęcka</h3><p>The rise of quantum computing presents a significant threat to classical cryptographic systems, particularly those relying on hard mathematical problems such as integer factorization and discrete logarithms. This paper explores the impact of quantum computing on traditional cryptographic algorithms and the necessity of transitioning to quantum-resistant cryptography. We provide an overview of post-quantum cryptographic (PQC) algorithms newly standardized by the National Institute of Standards and Technology (NIST) in the Federal Information Processing Standards (FIPS) 203, 204, and 205, which define quantum-secure key encapsulation and digital signature schemes. We examine existing implementations of these algorithms and evaluate the performance of  ML-KEM  against its classical alternative -- RSA. Our findings highlight the feasibility of deploying PQC in real-world systems by demonstrating that at high security levels, ML-KEM can achieve significantly faster operation speeds than RSA, proving its ability to provide both strong security and practical efficiency.</p>
<h1 id="21">Analysis and comparison of missing value imputation methods for atmospheric pollution data</h1><h3>Jakub Jasiński</h3><p>Missing values are a common phenomenon in real-world time series datasets and can significantly impact the precision and reliability of data analysis and machine learning models. This research project aims to discuss the types of missing data occurrence and test and analyze different possibilities of their imputation. The methods taken into consideration will start from the simplest ones based on statistics, go through regression models, neural networks, and finally LLMs.  The effectiveness of these imputation techniques will be measured and tested on atmospheric pollution data, primarily focusing on PM10, PM2.5, SO2, and NO2 levels. The performance of each method will be evaluated based on accuracy, consistency, and the impact on subsequent predictive models.</p>
<h1 id="23">Comparative Analysis of Machine Learning and Statistical Models for Short-Term Energy Production Forecasting in Poland</h1><h3>Jakub Karpiński</h3><p>This paper investigates short-term energy production forecasting in Poland using three distinct predictive models: LightGBM, an ARIMA-based model, and a Long Short Term Memory (LSTM) network. Leveraging historical data  from Poland’s energy sector, our study evaluates each model’s  performance in terms of accuracy, robustness, and computational  efficiency. The LightGBM model employs gradient boosting  techniques to capture non-linear relationships, while the ARIMA  approach provides a classical linear autoregressive approach.  Meanwhile, the LSTM network exploits its recurrent architecture  to model complex temporal dependencies inherent in the time-series data. Comparative analysis based on metrics such as  RMSE and MAE demonstrates that although all models exhibit  competitive forecasting abilities, the LSTM model exhibits a  modest performance advantage over the other approaches within  the examined forecast scenario. However, both the LightGBM  and ARIMA models offer advantages in terms of reduced computational overhead and ease of implementation. Furthermore,  I analyze ensemble models in search of the most accurate  predictions. The insights derived from this analysis aim to assist  policymakers and energy sector stakeholders in making informed  decisions regarding energy distribution and operational planning  in Poland.</p>
<h1 id="26">Verification of the authenticity of bullion coins with a mobile application based on frequency analysis using an artificial neural network</h1><h3>Tomasz Gryczka</h3><p>Counterfeiting of bullion coins is a serious issue for collectors, dealers and investors, highlighting the need for reliable and accessible authentication tools. This research presents a mobile application designed to authenticate bullion coins using audio analysis, offering an innovative and convenient solution. The app uses autoencoders, a form of artificial neural network, trained on spectrograms created from audio recordings of real coins being struck. These spectrograms capture unique frequency patterns, which the neural network analyses to recognise the acoustic signatures of authentic coins. Tests show that the application achieves high accuracy in distinguishing genuine coins from counterfeits, advancing non-destructive authentication methods. It offers practical benefits by allowing users such as collectors and dealers to instantly verify coins without special tools, increasing confidence in transactions. However, the performance of the application relies heavily on the quality of the audio recording, which can be affected by background noise or device limitations. The training dataset, while detailed, may not yet cover all coin types or counterfeit variations, which could reduce its effectiveness in some cases. Future efforts should aim to improve the application by expanding the dataset and incorporating additional data, such as weight or visual checks, to improve accuracy and versatility.</p>
<h1 id="29">Evaluating unsupervised data mining methods to assess the utility of such approaches for SIEM event analysis.</h1><h3>Marcin Dydo</h3><p>Modern organizations generate vast amounts of data, a significant portion of which consists of system, network, and application logs. The sheer volume and scalability of these logs make manual analysis inefficient and highly time-consuming. Automated anomaly detection techniques have been developed and refined to accelerate this process. Currently it is common for open SIEM systems to only support basic anomaly detection features. In our paper, we focus on unsupervised data mining methods for anomaly detection in time-series JSON data. This study compares and explores the utility of several anomaly detection algorithms applied to preprocessed data. The preprocessing stage includes time-bucket segmentation and feature extraction. We have also examined different approaches to preprocessing that are mentioned in the literature. Among the various methods, Isolation Forest and probabilistic algorithms like ECOD, have been proven to perform well on multidimensional semi-structured text datasets. Furthermore, we assessed the performance of selected methods using relevant Key Performance Indicators and compared them in different scenarios. Our findings suggest that some of these methods could be adapted to effectively support security analysts working with SIEM systems. Certain concepts developed within this proof-of-concept study could be further refined and integrated into a dedicated tool for log analysis.</p>
<h1 id="30">Comparing the Efficiency of Selected Reinforcement Learning Algorithms in Stability Control and Navigation Tasks</h1><h3>Oskar Wyłucki</h3><p>This paper presents a comprehensive comparison of the efficiency of four key reinforcement learning algorithms (DQN,  PPO, REINFORCE, and A2C) in stability control and navigation tasks. The study was conducted in two test environments: Cart Pole, representing a basic balance maintenance  task, and Lunar Lander, constituting a complex navigational  challenge requiring precise landing. As part of the research,  the algorithms were implemented using various neural network architectures adapted to the specific requirements of  each environment. For the Cart Pole environment, simpler  architectures were applied, while for the more complex Lunar Lander environment, enhanced networks with additional  learning process stabilization techniques were implemented,  such as layer normalization and orthogonal initialization.  The research methodology focuses on a systematic analysis  of key performance aspects, including convergence speed,  sample efficiency, adaptability to different initial conditions,  and learning process stability over time. For each algorithm  and environment, standardized experiments were conducted  with detailed performance metrics recorded throughout the  training process. The experiments revealed significant differences in how algorithms perform under varying levels of  environmental complexity.  The comparative analysis revealed significant differences  between algorithms in terms of learning approach, training  process stability, and ability to efficiently utilize accumulated  experiences. These observations emphasize that selecting an  appropriate algorithm strongly depends on the specifics of the  particular task, environmental complexity, and available computational resources. This research provides practical insights  into algorithm selection and configuration for reinforcement  learning tasks of varying complexity in the domains of stability  control and navigation.</p>
<h1 id="31">A Lung Volume-Based Perfusion SPECT and CT Comparison Algorithm for Enhanced Pulmonary Embolism Diagnosis</h1><h3>Daniel Kisiel, Eryk Muchorowski</h3><p>Pulmonary Embolism (PE) is reported to be one of the most  common cardiovascular diseases. It is caused by a blood clot  that develops in a blood vessel elsewhere in the body and  travels to an artery in the lung, forming a blockage.  Lung V/Q (ventilation/perfusion) SPECT is one of an established diagnostic imaging test for suspected PE. The idea  behind this test is to administer patient the radioactive tracer  intravenous or by inhalation and use a gamma camera to detect  the radiation emitted. The regular CT is also often performed  to improve diagnosis sensitivity and specificity.  II. PURPOSE  The goal is to develop an algorithm estimating lung volumes  from Perfusion SPECT and CT examinations and calculate the  ratio VP /VCT (Perfusion lung volume to CT lung volume).  The assumption is that a low ratio may indicate the presence  of regions with no perfusion, suggesting the patient may be  suffering from PE. This algorithm may improve the sensitivity  and specificity of PE diagnosis and introduces an automatically  calculated metric quantifying the severity of potential PE.  III. MATERIALS AND METHODS  During our studies, we developed a method for calculating  lung volumes using two complementary imaging modalities:  SPECT and CT. Our dataset comprised 5 patients — 3  diagnosed with Pulmonary Embolism (PE) and 2 healthy  controls. Both scans were available for each patient, acquired  through our collaboration with the Warsaw Military Institute  of Medicine.  Data processing involved analysis of DICOM files containing both CT and SPECT images along with their associated  metadata. For segmentation, we employed distinct approaches  tailored to each modality: SPECT images were segmented  using a standardized fixed threshold method, while CT images were processed using an established machine learning  algorithm based on transfer learning of U-net architecture,  implemented through the lungmask library. We improved  the CT segmentation process by converting pixel values to  Hounsfield Units (HU) as a crucial preprocessing step. Lung  volumes for both imaging modalities were calculated using  the physical voxel dimensions from the image metadata. This  dual-modality approach ultimately enabled us to calculate the  Perfusion/CT ratio based on the segmented volumes.  IV. RESULTS  The developed algorithm successfully distinguished between PE-diseased and healthy patients. The maximum volume ratio observed in the diseased group was 0.695, while  the minimum value in the healthy group was 0.869.  V. CONCLUSION  Although the algorithm effectively differentiated between  the two groups, the limited sample size suggests the need for  further research and additional data to validate the findings,  determine a reliable threshold, and establish fundamental  metrics such as sensitivity and specificity.</p>
<h1 id="34">Comparison of Models for Automatic Description of Medical Images</h1><h3>Jakub Urbański</h3><p>Automated medical report generation from chest X-ray images is a critical area of research in medical AI, aiming to enhance diagnostic accuracy, reduce radiologists' workload, and improve patient care. The process involves analyzing medical images and translating visual findings into structured, clinically relevant textual reports. Traditional methods rely on human expertise, which is time-consuming and prone to variability, motivating the development of deep learning-based solutions that leverage vision-language models to automate this task. This project explores and compares state-of-the-art deep learning architectures for medical report generation, evaluating their capabilities in image encoding and text generation. The study considers convolutional neural networks (CNNs) such as ResNet, vision transformers (ViTs) like SwinTransformer, and state space models (SSMs) such as Mamba for extracting visual features. The text generation stage utilizes recurrent neural networks (RNNs) such as LSTMs and GRUs, as well as transformer-based architectures such as BioClinicalBERT, LLaMA-2, and GPT-style decoders. The models being evaluated include BioViL-T, R2Gen, MedCLIP, PLIP, CheXbert, and MambaXray-VL, trained and tested on datasets such as IU X-Ray and CheXpert. This study aims to systematically assess different architectural approaches, training methodologies, and dataset utilization strategies to provide insights into their advantages and limitations in generating clinically meaningful radiology reports.</p>
<h1 id="35">Zastosowanie modeli GAN do usuwania artefaktów z sygnału EEG</h1><h3>Małgorzata Sokół</h3><p>Sygnał elektroencefalograficzny (EEG) może ulegać zakłóceniom spowodowanym przez aktywność elektryczną niezwiązaną bezpośrednio z pracą mózgu badanego. Zjawisko to określane jest jako problem artefaktów EEG, które dzielimy na techniczne i fizjologiczne. Do artefaktów fizjologicznych należą charakterystyczne fragmenty sygnału rejestrowane w wyniku ruchów gałek ocznych, mrugania, czy aktywności mięśniowej. W celu eliminacji tych zakłóceń opracowano wiele metod, spośród których najczęściej stosowane to ślepa separacja sygnałów, empiryczna dekompozycja modalna oraz transformata falkowa. Kluczowym wyzwaniem jest minimalizacja utraty istotnych informacji podczas usuwania artefaktów. W ostatnich latach coraz większą popularność zyskują metody wykorzystujące uczenie maszynowe. Szczególnie obiecujące wyniki uzyskano dzięki zastosowaniu sieci konwolucyjnych, autoenkoderów oraz sieci GAN. Techniki te mają potencjał adaptowania się do eliminacji artefaktów o różnorodnej charakterystyce. W artykule przedstawiono wyniki zastosowania sieci GAN wraz z dodatkowymi sygnałami artefaktu w celu eliminacji artefaktów fizjologicznych. Modele były trenowane na danych syntetycznych zawierających artefakty typu EOG oraz EMG. Uzyskane wyniki sugerują, że zastosowanie sieci GAN w połączeniu z sygnałami EMG może skutecznie wspomóc usuwanie artefaktów fizjologicznych z zapisu EEG.</p>
<h1 id="39">Exploring LLMs mathematical reasoning capability: Insights from GSM-Symbolic in English and Polish</h1><h3>Marcin Łomiński, Michał Tomczyk</h3><p>Large language models (LLMs) are trained with ever-increasing amounts of data. It seems that when asked to solve mathematical tasks, they can infer and reason mathematically. The GSM8K benchmark platform is widely used to test various LLMs to solve simple arithmetic tasks. Recently, LLMs have shown a clear improvement in their ability to correctly answer questions from the GSM8K dataset. However, it is impossible to say conclusively from the GSM8K studies whether the performance increase was also followed by improvements, in the mathematical reasoning mentioned above. A recent study that shed light on the problem of mathematical reasoning in LLMs attempted to address this problem by creating a database based on GSM8K but with the ability to make appropriate changes to the content of math tasks, which would test how true the claim that LLMs can reason is.  In our research, we have attempted to confirm previously established research results, but also to extend them to include newly developed language models such as DeepSeek or more advanced versions of ChatGPT. Above that, the research was also extended to check the influence of the language in which the test math tasks were written on the effectiveness of a given model. We decided to translate the GSM-Symbolic datasets using the Google Translator API, creating Polish equivalents, which we have provisionally named GSM-Symbolic-PL, GSM-P1-PL, GSM-P2-PL. The selected LLMs are then questioned hundreds of times using the 3-shot Chain-of-Thought prompting method, which involves giving the model 3 sample questions and answers to indicate how the model should ”think” when generating and answer to the final question. Using it is supposed to allow LLMs to be more directed towards proper mathematical thinking and reasoning which we want to investigate. After that, the results were validated and analyzed.  Our research was focused on ChatGPT versions 4o-mini and o3-mini and DeepSeek’s latest versions V3 and R1. As expected, the model’s responses depend on the content of the task and is strongly dependent on whether bias is placed in the task, in which case the model makes errors very often. This seems to indicate that LLMs might not be able to reason mathematically the way humans do. Their answers are inconsistent, even though the reasoning path to solve the task remains the same. GSMSymbolic, compared to GSM8K, exposed this weakness even more, but this does not change the fact that the higher models’ correctness of response is quite high.</p>
<h1 id="40">Franky: An Intelligent Agent for Stock Portfolio Management Using Large Language Models and Deep Reinforcement Learning</h1><h3>Mateusz Bartosik, Mikolaj Zawada</h3><p>I. INTRODUCTION  This paper introduces an innovative intelligent trading agent  designed for autonomous stock portfolio management, integrating Large Language Models (LLMs) and Deep Reinforcement Learning (DRL). The core objective was to develop a  trading agent capable of effectively managing a diversified  stock portfolio by synthesizing quantitative market data with  qualitative insights derived from real-time financial news and  corporate reports.  The motivation behind this approach arises from limitations  observed in conventional trading algorithms, which predominantly rely on historical price data and technical indicators  while frequently neglecting critical qualitative information.  Existing market solutions typically separate numerical analysis  and text-driven sentiment analysis, thus failing to fully exploit  the synergistic potential of these data sources. By contrast, the  proposed method uniquely integrates these elements through  a combined architecture inspired by FINMEM and FinRL frameworks.  The proposed system operates through a multi-layered approach, employing DRL agents trained on historical numerical  data and stock-specific memory module that prioritize and  manage textual information. Memory module continuously  captures, processes, and contextualizes incoming data streams  into structured, actionable insights. Data is being scraped and  processed in real-time from predefined and trusted sources on  the Internet, allowing a rapid reaction to ever changing market  environment. LLM serve as an advanced interpretative engine,  conducting sentiment and contextual analyses of news articles  to anticipate market reactions. DRL Agent is responsible for a quantitative analysis of portfolio assets and suggesting an  optimized resources allocation. It considers how assets move  relative to each other, risks associated with each asset, technical indicators and historical data. Agent is using the Advantage Actor-Critic algorithm that, after a series of backtesting, outperformed DDPG, PPO, TD3 and SAC by around 5% -  20%. Ultimately, stock-level recommendations are integrated  by a dedicated portfolio-level LLM, considering portfolio  constraints, diversification, risk tolerance, and available funds  to formulate cohesive and strategic trading decisions. As many LLMs of various architectures are currently available, such a  selection of them was taken into consideration which enabled verification of the difference between reasoning and non-reasoning models.  Validation of the system’s performance was conducted  through rigorous backtesting across diverse historical market  conditions, employing metrics such as cumulative returns  and risk-adjusted returns against benchmark trading strategies.  Initial results (return of around 36%) demonstrate the superior  performance and adaptability of the proposed system, outperforming conventional DRL-based and purely sentiment-based  methods, particularly in volatile market conditions.  Future development will concentrate on optimizing the  portfolio manager component, exploring dynamic rebalancing  strategies and refining its scalability and adaptability to real-time trading environments. This work not only enhances  autonomous trading technologies but also provides valuable  insights into how hybrid AI architectures can revolutionize  financial market analysis and decision-making.</p>
<h1 id="41">Automatic translation of Japanese manga using MultiModal Large Language Models</h1><h3>Tomasz Nitsch</h3><p>Japanese manga has captivated readers worldwide with its vibrant and expressive form of art that provides compelling storytelling with intricate visuals. However, for many fans outside of Japan, language barriers often stand in the way of fully experiencing the depth of these stories. Traditional translation from language to language, while effective, can be a very time-consuming and labor-intensive process that requires teams of translators, editors, and cultural consultants to convey the essence of the original text accurately. The difficulty with Japanese is even greater, as it is a heavy-context-intensive language.  Machine translation is nothing new; we try and fail with basic translation from language A to language B, and Google Translate is its finest example. Large language models (LLMs) and with its new type, multimodal LLMs, have undergone substantial advancements, augmenting already powerful LLMs to support multimodal inputs or outputs via cost-effective training strategies. Those showed potential in many works such as coding, answering complex math questions, or understanding symbolism within texts. In this paper, we conduct a substential investigation on how well certain MMLLMs work against manga translation. We create benchmarks with text-only-wise; image-from1page-context; as well as whole volume thus far.   Although the results were sometimes satisfactory, they proved to be insufficient to be a standalone automatic translator, as translations were not understandable and/or too complex or too simple at times. However they prove to provide enough understanding of context to, with some human element, come up with accurate translation</p>
<h1 id="42">Proxy Methods in Image Recognition</h1><h3>Barbara Borkowska, Marcin Maciąg</h3><p>This paper presents a comprehensive comparison of several state-of-the-art proxy loss methods for retail product recognition, focusing on accuracy, computational efficiency, embedding quality, and convergence behaviour. An extensive evaluation is performed on the Stanford Online Products benchmark dataset, which contains over 120,000 images covering 22,634 distinct product categories. The analysis reveals a trade-off between proxy-based and non-proxy-based methods, highlighting the conditions under which each approach may be more advantageous. Attention is also given to identifying optimal model parameters for individual proxy methods, offering insights into their most effective configurations. The findings underscore the importance of balancing computational efficiency and embedding quality when deploying proxy loss methods for large-scale product recognition tasks.</p>
<h1 id="45">Optimizing Football Betting Strategies Using Deep Neural Networks and Modern Portfolio Theory</h1><h3>Daniel Kuciński, Tomasz Mycielski</h3><p>This paper presents a hybrid framework combining Deep Neural Networks (DNNs) and Modern Portfolio Theory (MPT) to optimize football betting strategies. Leveraging historical match data from five major European leagues (2014–2025), we engineer predictive features such as dynamic Elo rankings, expected goals (xG), and team performance metrics derived from raw game statistics. Diverse neural architectures, including convolutional (Conv1D) and recurrent (LSTM, GRU) layers, are systematically explored to capture spatial and temporal patterns in match outcomes and goal totals. Automated Machine Learning (AutoML) techniques further refine model selection and hyperparameter tuning, ensuring robustness. MPT principles are then applied to balance risk and return, evaluating strategies ranging from threshold-based betting to a modified Kelly Criterion. The synergy of advanced predictive modeling, automated architecture optimization, and systematic risk management provides a scalable, data-driven pathway to sustainable profitability in sports betting.</p>
<h1 id="47">Testy penetracyjne systemu zarządzania energią elektryczną OpenEMS — identyfikacja i mitygacja podatności w otwartoźródłowych systemach energetycznych</h1><h3>Kacper Gorlowski</h3><p>W odpowiedzi na rosnącą popularność rozproszonych systemów zarządzania energią oraz integrację odnawialnych źródeł energii (OZE), w projekcie przeprowadzono kompleksową analizę bezpieczeństwa otwartoźródłowego systemu OpenEMS. System ten, napisany w języku Java, wspiera monitorowanie, kontrolę i optymalizację przepływów energii elektrycznej w instalacjach przemysłowych i prosumenckich. Celem projektu była identyfikacja krytycznych podatności w systemie oraz ocena ryzyka dla integralności, dostępności i poufności danych w kontekście systemów zarządzających infrastrukturą energetyczną. Zidentyfikowano problematykę związaną z brakiem powszechnie dostępnych analiz bezpieczeństwa otwartoźródłowych systemów EMS, mimo ich rosnącego znaczenia w przemyśle i energetyce. W trakcie badań przeprowadzono testy penetracyjne obejmujące, analizę kodu źródłowego i komponentów backendu, testy dynamiczne interfejsów REST API, ocenę bezpieczeństwa warstwy komunikacji Modbus TCP, badanie podatności na typowe błędy programistyczne i konfiguracyjne. Do realizacji testów wykorzystano m.in. środowiska OWASP ZAP, Burp Suite, a także specjalistyczne narzędzia dedykowane testowaniu systemów OT i aplikacji webowych. Przeanalizowano krytyczne błędy w kodzie źródłowym oraz zaproponowano zmiany w konfiguracji komunikacji sieciowej, zwiększające odporność systemu na ataki. Projekt dostarczył istotnych wniosków naukowych, pogłębiając wiedzę z zakresu cyberbezpieczeństwa otwartoźródłowych systemów klasy EMS. Wyniki badań wykazały powtarzalne wzorce podatności charakterystyczne dla tego typu rozwiązań i potwierdziły konieczność łączenia podejścia IT z praktykami ochrony infrastruktury krytycznej (OT). Z perspektywy praktycznej i komercyjnej projekt przyniósł mierzalną wartość dla podmiotów wdrażających OpenEMS w rzeczywistych instalacjach przemysłowych i prosumenckich. Opracowane rekomendacje mogą zostać bezpośrednio wykorzystane w audytach bezpieczeństwa oraz jako podstawa dla dalszego rozwoju systemu, zwiększając jego odporność na zagrożenia cybernetyczne.</p>
<h1 id="48">Enhancing Large Language Models with Retrieval-Augmented Generation: A Case Study on Movie Data Beyond the Training Cutoff</h1><h3>Marcel Mikołajczyk</h3><p>This article investigates the role of Retrieval-Augmented Generation (RAG) in enhancing Large Language Models (LLMs) with information about movies and TV series released beyond their training data. In this study, the Llama 3.2 3B LLM is leveraged and integrated with external movie-related data retrieved from the OMDb API to provide specific information about over 14000 titles released in 2024, which fall outside of the LLM's knowledge cutoff. This approach aims to improve the accuracy, reliability, and contextual relevance of LLM responses by utilizing movie metadata and precomputed embeddings for information retrieval. The incorporation of these techniques enables the system to efficiently identify plot connections, verify directors and cast members, and analyze trends in the latest movie productions. Moreover, the research examines RAG's potential in mitigating LLM hallucinations by providing reliable external knowledge and adaptive query processing. The results aim to support film critics, analysts, and movie enthusiasts by providing the latest film-related data, while also highlighting the effectiveness of RAG in fields where access to specialized, dynamic knowledge is crucial.</p>
<h1 id="50">Ethereum price forecasting using deep neural networks</h1><h3>Oskar Rozwadowski</h3><p>Short-term forecasting of cryptocurrency prices remains a challenging task due to the high volatility and complex market dynamics of digital assets like Ethereum. This study proposes a hybrid deep learning model, that integrates networks such as Bi-LSTM, FinBERT and GRU, seeking to provide a comprehensive analysis of their applicability in this domain and enhance predictive accuracy for this currency. It incorporates news sentiment analysis as an additional predictive feature, aiming to capture broader market sentiment trends. The model was trained using historical Ethereum price data, along with trading volume, technical indicators, and sentiment scores extracted from news sources. Results indicate that the hybrid model outperforms traditional standalone models, suggesting that combining multiple architectures improves short-term price forecasting. However, challenges such as sentiment data noise and potential overfitting highlight areas for further refinement.</p>
<h1 id="51">Pose-Based Motion Analysis for Physical Exercise Quality Assessment</h1><h3>Wojciech Jakieła</h3><p>This paper presents a comprehensive approach to the evaluation of physical exercise using skeletal estimation and motion analysis. The research begins with the acquisition of relevant datasets and a review of existing monocular pose estimation solutions. A key component of this work is modeling important features, including skeletal joint weighting and key angles between them, according to their relevance for specific exercises. The synchronization of reference and analyzed recordings is achieved using Dynamic Time Warping (DTW), enabling accurate comparison and alignment.   We propose a method to determine the correct measure of consistency between reference and estimated trajectories, along with setting DTW distance thresholds based on performance quality. Finally, the effectiveness of the developed solution is assessed, and strategies for its optimization are discussed. The proposed approach offers valuable insights into improving motion estimation accuracy for exercise monitoring and analysis.</p>
<h1 id="1">Perception manipulation and subjective reception of data</h1><h3>Filip Horst</h3><p>The aim of this paper is to provide insight into how the recipients’ opinions may be manipulated in data visualization scenarios. To obtain trustworthy and representative results, the study involved an experiment, in which participants solved tasks with charts that were purposefully modified to alter their perception of the data. The results indicate that this type of unethical action can be effective, occasionally causing over 40% of the recipients to be wrong or confused. Despite the limitations such as a low number of participants, the observations made during this study can be interpreted as a warning that misinformation is a real threat. More research should be carried out to provide the tools and information necessary to raise public awareness even further.</p>
<h1 id="3">BBot - Behavioral reinforced learning bot to play blood bowl</h1><h3>Bartosz Nowicki, Karol Kociołek, Wiktor Wołek</h3><p>This paper presents a comparative study of different neural network architectures trained using behavioral learning in the strategic board game Blood Bowl. The game’s complexity, driven by its large branching factor and inherent randomness, presents a significant challenge for artificial intelligence (AI). Traditional AI approaches, such as scripted and search-based methods, have struggled to achieve human-level performance. This study examines how various deep learning models process decision data, adapt strategies, and handle uncertainty in gameplay. Our methodology involves training models with a custom preprocessing pipeline that extracts valid game states and actions from replays of scripted solutions and tournament self-play. Performance is evaluated by competing against existing AI solutions, using metrics such as win rates, move efficiency, and strategic accuracy. The results highlight the comparative strengths and weaknesses of each architecture, providing insights into their effectiveness for reinforcement learning-based agents in complex decision-making environments like Blood Bowl.</p>
<h1 id="4">Comparison of multiplatform technologies for mobile application development</h1><h3>Michał Ankiersztajn</h3><p>This paper compares technologies used to develop mobile applications using multiplatform technologies. A lack of analysis of newer technologies, such as Kotlin Multiplatform, was identified by researching the current state of this field. Therefore, this study aims to compare the Kotlin Multiplatform with existing and well-researched Flutter technology to advance mobile development techniques. A comparison has been drawn from both literature and practice.</p>
<h1 id="5">Attacks on LSTM-Based Recurrent Neural Networks for Sentiment Analysis</h1><h3>Rafał Zan</h3><p>Recurrent Neural Networks (RNN) and their other variants such as Long-Short Term Memory (LSTM) networks have become a widely used tool for natural langague processing (NLP). Thanks to their ability to effectively capture sequential dependencies in textual data they are well-suited for determining sentiment expressed in user-generated data such as media posts or reviews. However despite their effectiveness we cannot forget about their vulnerability for intentional perturbations in the input data possibly affecting their classification capabilities. This work is aimed to analyze impact of such manipulations on LSTM and non-LSTM based networks. The analysis was conducted on custom-made RNNs trained on database containing game reviews on Twitter. Research will involve specificaly two types of input data manipulations - synonymization and token replacement with the most semantically similar vectors. This work presents the effects of experiments comparing the aforementioned networks' resilience to perturbations and the way they affect model's classification abilities. Final findings suggest that LSTM models exhibit greater resistance to subtle input changes (using synonyms) than standard RNNs but remain susceptible to more advanced attacks (vector replacement). This study highlights the importance of research in domain of neural networks' security and opens new paths for future study in this direction.</p>
<h1 id="7">User experience laws: a literature review and practical examples based on DoorCE project</h1><h3>Jerzy Balcer</h3><p>The article presents a detailed literature review on the topic of user experience design principles. The study synthesizes knowledge from research papers and books, focusing on user experience laws that can be applied while designing user interfaces. The review highlights sources about Gestalt psychology in user experience design. The studied literature also emphasizes the importance of Miller’s Law and Hick’s Law regarding the complexity and Fitt’s Law related to efficient layouts. Moreover, articles discussing navigational patterns such as Z-pattern and F-pattern are analyzed. In addition, sources on methods of increasing user interface accessibility are examined. Lastly, the article summarizes findings about consistency as a crucial element of user experience. Based on the reviewed literature, the author presents practical examples. Examples come from two user interface prototypes of the DoorCE project – a joint initiative of many Central European institutions to make public data more accessible. These user interfaces are evaluated based on described laws and corrections are made where necessary. The result of this research is a set of design principles based on the current state of the art, each with its own example from a professional application.</p>
<h1 id="8">Overview of Communication Mechanisms Adopted in Modern Systems</h1><h3>Jakub Szczygielski, Michał Żdanuk</h3><p>In modern software systems, efficient communication is essential for ensuring scalability, maintainability, and performance. The aim of this article is to review key communication mechanisms used in modern systems. A multi-stage selection process was conducted to identify the most relevant scientific articles, summarize research findings, and determine which methods perform best in specific contexts. The search was carried out using selected electronic databases of scientific publications. Research indicates that REST is widely used and performs well,  GraphQL is effective for retrieving large datasets, and gRPC enables fast data transfers. Additionally, Kafka, MQTT, and AMQP are the most suitable protocols for handling messaging in high-load distributed systems. The study emphasizes that choosing the right communication method is crucial and should consider specific system requirements such as data volume, speed, security, and the type of operations involved.</p>
<h1 id="9">Development of a model of the electric field distribution inside the human brain</h1><h3>Konrad Trusiewicz, Mikołaj Guryn, Zuzanna Gaik</h3><p>This study focuses on optimizing the computational efficiency of simulating electric field distribution in the human brain using the finite element method (FEM). Due to the brain’s complex and heterogeneous structure, accurate modeling requires high-resolution segmentation and realistic electrical property assignments, leading to large-scale numerical problems. To address these challenges, this research explores advanced numerical solvers, parallel computing strategies, and memory-efficient algorithms to enhance performance without compromising accuracy. Special attention is given to optimizing matrix assembly, preconditioning techniques, and load balancing in parallel computations, enabling faster convergence and reduced memory consumption. This study also investigates the performance of algebraic multigrid solvers, including the Ruge-Stuben AMG and Smoothed Aggregation AMG methods, to efficiently handle the large, sparse linear systems arising from FEM simulations. Additionally, we implement parallelized matrix assembly in Julia using distributed computing and shared memory techniques to optimize workload distribution and reduce communication overhead in large-scale simulations.</p>
<h1 id="12">Comparative Analysis of Continuous Software Delivery Tools Using Github Actions and Jenkins as Examples</h1><h3>Paweł Prokopiuk</h3><p>Continuous integration and continuous deployment (CI/CD) tools are fundamental to modern software development, enabling automated software delivery and deployment. While numerous CI/CD solutions exist, this study focuses on a comparative analysis of GitHub Actions and Jenkins, two widely used tools representing cloud-based and self-managed CI/CD solutions, respectively. The evaluation covers key aspects such as scalability, configuration complexity, integration capabilities, cost, stability, and resource consumption. Through empirical testing and case studies, the study examines their effectiveness in building, deploying, and testing software, as well as their ability to integrate with third-party platforms and optimize infrastructure usage. The results show that GitHub Actions offers seamless integration with the GitHub ecosystem, simplified setup, and cost-effective scalability, making it particularly suitable for small to mid-sized teams that rely on cloud-native workflows. Conversely, Jenkins offers extensive customization, advanced plugin support, and greater flexibility, making it the preferred choice for large enterprise environments requiring on-premises or hybrid infrastructure. This study highlights critical decision factors when choosing a CI/CD platform, including installation methods, infrastructure control, and long-term maintenance requirements. The findings contribute to a broader understanding of the trade-offs between cloud-native and self-managed CI/CD solutions, and provide insights applicable to evaluating other CI/CD tools in different development environments.</p>
<h1 id="13">Wpływ stopnia sprzężenia klas na czas wprowadzenia zmian - badanie empiryczne</h1><h3>Dawid Pura</h3><p>Zmiany w oprogramowaniu stanowią największą część kosztów ponoszonych podczas jego utrzymywania. Optymalizacja kosztów, a w szczególności czasu poświęconego na wprowadzanie zmian umożliwia organizacjom utrzymującym oprogramowanie uzyskanie przewagi konkurencyjnej. Kluczową aktywnością w modyfikacji kodu źródłowego jest jego zrozumienie, na co wpływ ma zastosowana struktura klas.  Prezentacja przedstawia eksperyment przeprowadzony na 10 programistach, przed każdym z nich postawiono dwa zadania dostosowania programu do nowych wymagań. Pierwsze zadanie stanowiło próbę kontrolną i obejmowało obszar wspólny dla obu wariantów programu. Zmierzony czas został wykorzystany jako baza normalizacji wyników badania w celu kontroli zmiennych zakłócających. Dla połowy z badanych kod źródłowy został zmodyfikowany metodą odwróconej refaktoryzacji, która zwiększyła metrykę sprzężenia *Message Passing Coupling* dwukrotnie w obszarze zadania drugiego.  Eksperyment został poprawnie przeprowadzony w 9 na 10 przypadków. Znormalizowany czas zadania drugiego wykazał 73% różnicę pomiędzy grupami, jednocześnie t test Welcha t = -3.23 p = 0.01 co ugruntowuje wynik jako statystycznie istotny.  Wyniki badania potwierdzają założenie praktyków, że w celu przyszłych oszczędności w obszarze dostosowywania oprogramowania programiści powinni utrzymywać sturuktury kodu o możliwie najniższym sprzężeniu klas. Jednocześnie wskazuje, że istotnym elementem poprawnego przeprowadzenia eksperymentu jest jednolity dostęp do informacji, a przyszłe próby odtworzenia powinny opierać się o większe grupy z zachowaniem niższych kosztów samego badania, wykorzystując technologię kontrolowanych środowisk programistycznych, używaną dziś w ocenie zdolności programistycznych.</p>
<h1 id="18">Flutter vs. React for Web Applications: A Comparative Benchmark Study of Performance Metrics and Developer Experience</h1><h3>Jakub Witczak</h3><p>Rapid growth in device types used for running applications created a need for tools that allow cross-platform development.   This paper aims to benchmark multiple metrics, such as build size and speed index, to determine if Flutter is a good choice for writing web applications. Additionally, this research analyzes developer experience factors to provide a comprehensive evaluation beyond performance metrics alone.  Results of the performed benchmark show that React is better in most of the chosen metrics. The build sizes of Flutter applications are multiple times bigger, affecting the time needed to load initial chunks when the user first enters the website. Flutter architecture requires it to load its render engine so that the user can see content in the browser. These findings suggest that while Flutter offers the benefit of a unified codebase, its current performance limitations on the web can hinder its adoption for production-grade applications. Despite Flutter's comprehensive documentation, the web-specific guidance was noticeably less mature than React's extensive community resources and well-established best practices for web development.</p>
<h1 id="22">Badania i Implementacja Innowacyjnego Systemu Zasobnika Energii Współpracującego z Odnawialnymi Źródłami Energii INNOSTOR dla Zrównoważonego Rozwoju na Politechnice Warszawskiej</h1><h3>Adam Sadowski, Dorota Szulc, Jakub Ćwiek, Jan Kowalik, Krzysztof Jęczmieniowski, Ryszard Kucharski</h3><p>W artykule przedstawione zostały dotychczasowe postępy projektu *Badania i Implementacja Innowacyjnego Systemu Zasobnika Energii Współpracującego z Odnawialnymi Źródłami Energii INNOSTOR dla Zrównoważonego Rozwoju na Politechnice Warszawskiej* realizowanego przez koło naukowe IskIErka w ramach grantu rektorskiego. Opisany został ogólny kierunek zmian w elektroenergetyce, dążący do coraz większego udziału źródeł odnawialnych w miksie energetycznym. Omówiona została związana z tym zagadnieniem problematyka nadpodaży energii elektrycznej w KSE i niedopasowania krzywej generacji do krzywej obciążenia. Przedstawiona została perspektywa prosumenta jako uczestnika wspomnianych procesów. Zarysowano możliwe rozwiązania tych problemów, ze szczególnym uwzględnieniem lokalnych magazynów energii elektrycznej, współpracujących ze źródłami odnawialnymi, w ramach instalacji prosumenckich małej mocy. Zaprezentowano projekt układu oferującego optymalne warunki prowadzenia badań w tej tematyce. Omówiono kwestię doboru odpowiednich urządzeń wytwórczych i magazynów energii, wraz z ich parametrami. Przedstawiony został obecny postęp prac oraz zebrane dotychczas pomiary. Na ich podstawie wyciągnięte zostały pierwsze wnioski. Opisane zostały dalsze etapy realizacji projektu, a także jego końcowe cele i perspektywy.</p>
<h1 id="25">Spatio-Temporal Memory System for Robots: Enabling Long-Term Contextual Reasoning</h1><h3>Maciej Majek</h3><p>Enabling robots to operate autonomously in dynamic environments over extended periods requires robust memory, reasoning, and decision-making capabilities. Although large language models (LLMs) have demonstrated significant potential, their limited context size constrains their ability to manage long-term data effectively. Autonomous systems must be able to provide detailed information about a robot’s past actions, locations, and observations—critical for supporting human decision-making and ensuring reliable long-term operation.  To address this challenge, we introduce a Spatio-Temporal Memory System integrated into the RAI framework. This system enables robots to collect, organize, and reason over data accumulated over hours, weeks, or even months. By capturing and structuring spatial, temporal, and visual information, it allows robots to efficiently retrieve relevant data and respond to complex queries with high accuracy and speed.  The system operates through two parallel processes: memory construction and query execution. This design ensures continuous data collection while enabling real-time user queries. To facilitate scalable and efficient data retrieval, the architecture integrates vector databases and NoSQL storage. In addition, it supports multimodal data processing, location- and time-based indexing, and semantic search, significantly improving the ability of a robot to recall and reason about past experiences.  Real-world evaluations demonstrate the effectiveness of the system in improving autonomous decision making and long-term adaptability. This work presents a scalable and practical solution for robots that navigate complex and evolving environments. The implementation is open source and available at: https://github.com/RobotecAI/rai</p>
<h1 id="27">Projekt uniwersalnego robota modularnego</h1><h3>Feliks Brzeziński, Kacper Olszewski, Patrycja Płodowska</h3><p>The objective of this work is to present the modular robot Gizmo, focusing on its mechanical design, the concept of a distributed control system, and the inter-module communication protocol. The paper also discusses the physical model constructed using 3D printing. Each segment of the robot is equipped with independent actuators and the ability to connect and reconfigure. These characteristics enable modular robots to adopt various topologies, facilitating the development of manipulators, mobile robots, or legged robots. Additionally, the article explores potential applications spanning across industries and the educational sector.</p>
<h1 id="28">HDR - the impact of input parameters on the result for Debevec algorithm</h1><h3>Jakub Maciejewski, Michał Ziober</h3><p>Humans can perceive a much broader luminance range than an average camera. It is impossible to take a single photo that contains details for both very dark and bright areas.  HDRI (High Dynamic Range Imaging) methods address that problem, by merging multiple low dynamic range images (LDR) into a single picture. These methods are being used for professional cameras and even in smartphones.  The purpose of this article is to examine the optimal input parameters, including, among others, the number of images, their exposure times, and weighting functions using the Debevec-Malik method.  The images were taken from various scenes. Each scene was captured multiple times (in RAW and JPEG format) with different exposure duration, but with constant sensitivity and aperture. The experimental setup featured a stationary Nikon D40 camera mounted on a tripod. Photos had to be taken in the shortest possible time to avoid problems caused by movement within the scene, including clouds and people.  Multiple combinations of input parameters were investigated to create HDR images for every scene. In this paper, the histograms of both the composite HDR images and their individual source frames were examined. In addition, HDR images were evaluated in terms of noise characteristics, color fidelity, and overall realism. Finally, the radiance map and the camera response curve were analyzed to provide detailed information on image quality and dynamic range.  Each additional photo with a different exposure provides new information about the scene, potentially improving image quality and reducing noise. However, as will be shown, there is no need to use an excessively high number of images, as the benefits diminish rapidly after a certain point. Therefore, a smaller number of images can be used, resulting in faster processing times.  This research could be further expanded by incorporating a light meter to compare the obtained measured values with calibrated HDR image radiances. Additionally, exploring different HDR imaging approaches, pixel selection methods, and weight functions could help refine and validate the proposed methods.</p>
<h1 id="33">Przegląd znakowania wodnego obrazów we współczesnych zastosowaniach</h1><h3>Adam Pilewski, Mikołaj Kordowski</h3><p>Dynamiczny rozwój sztucznej inteligencji oraz mediów społecznościowych zwiększają potrzebę skutecznej ochrony przekazywanych danych. Znakowanie wodne jest jedną z możliwych technik modyfikujących m. in. obrazy w celu śledzenia przepływu informacji i pochodzenia. W niniejszej pracy przeanalizowano różne techniki znakowania wodnego, obejmujące zarówno tradycyjne algorytmy, jak i nowoczesne systemy oparte na głębokich sieciach neuronowych. Celem badań było porównanie odporności tych metod na różne aktualnie występujące ataki w mediach społecznościowych. Do eksperymentów wykorzystano rozbudowany zbiór danych zawierający zdjęcia o zróżnicowanych parametrach. Na każdy obraz został nałożony znak wodny, który w następnych etapach był atakowany. Największy wpływ na ekstrakcję znaku wodnego miały ataki takie jak kompresja stratna JPEG, rozmycie obrazu oraz dodanie szumu. Po każdym kroku były zbierane metryki takie jak BER, QualiCLIP, LPIPS, SSIM, na podstawie których oceniano skuteczność algorytmów. Eksperymenty wykazały, że ataki bazujące na kompresji stratnej oraz rozmywaniu obrazu miały największy wpływ na ekstrakcję znaku wodnego, utrudniając odzyskanie osadzonych znaków w przeciwieństwie do ataków opartych na szumie, które miały niewielki wpływ. Metoda naiwna, wykorzystująca obraz źródłowy przy dekodowaniu, wykazuje najlepszą przeżywalność ataków. Metody oparte na głębokich sieciach neuronowych również okazały się skuteczne, jednak ich czas działania był znacząco dłuższy.</p>
<h1 id="36">Blazor WebAssembly and React comparison</h1><h3>Antoni Olszewski</h3><p>The choice of a frontend framework significantly impacts the performance, maintainability, and scalability of modern web applications. This paper presents a comparative analysis of Blazor and React, two popular frontend frameworks with distinct architectures and approaches to building web interfaces. Blazor, developed by Microsoft, leverages C# and .NET to enable web development using WebAssembly or server-side rendering. React, maintained by Meta, is a widely adopted JavaScript library that utilizes a virtual DOM and component-based architecture.   This study compares the performance of React and Blazor by replicating a set of benchmarks focused on measuring rendering efficiency. The benchmarks analyze three key scenarios: rendering static elements, rendering a large number of child components, and constructing a binary tree component hierarchy. By measuring the time required for each rendering operation, this research provides insights into the performance characteristics of these frameworks, highlighting their strengths and weaknesses in different rendering scenarios.</p>
<h1 id="37">Machine Learning-Based Examination of ESG Factors in Stock Predictions</h1><h3>Daniel Stańkowski, Daniel Ślusarczyk, Paweł Tęcza</h3><p>This paper explores the relationship between carbon reduction efforts, ESG factors and financial performance. Machine learning models are applied to multi-industry data to assess whether carbon-related ESG attributes - such as carbon emissions and participation in emissions trading schemes - enhance the prediction of stock returns. The analysis also considers the concept of a carbon premium, understood as the excess return investors may require from firms with high greenhouse gas emissions. The findings indicate that, although such ESG indicators are widely disclosed, their inclusion does not consistently improve model accuracy and, in some cases, diminishes predictive performance due to data gaps and increased complexity. The results suggest that ESG-related factors, particularly those linked to carbon emissions, may not directly or immediately influence a firm’s financial returns, underscoring the need for more comprehensive data to evaluate their long-term significance.</p>
<h1 id="43">Threat Detection in IIoT Networks through Deep Packet Inspection and Machine Learning Mechanisms</h1><h3>Jan Guziuk, Hubert Masłowski</h3><p>The rapid expansion of Industrial Internet of Things (IoT) networks has increased security vulnerabilities, necessitating robust threat detection mechanisms. Industrial networks may hold non-critical data and confidential energy or medical data. The second group should therefore be covered by stringent security policies against Denial of Service attacks or attempts to steal information through an unsecured network segment. The traditional approach to analyzing network traffic is to classify packets as suspicious based only on the initial layers of the TCP/IP model; such a solution is sufficient for security policies designed to ensure business continuity of systems, but rejects the possibility of advanced detection based on application layer protocols investigation. Therefore, modern threat detection solutions have security capabilities extended with the DPI (Deep Packet Inspection) technique, using application layer data analysis for security improvement.   This research investigates the effectiveness of deep packet inspection (DPI) and machine learning (ML) techniques in detecting cyber threats across protocols like MQTT, SNMP, and Modbus. Using the pipeline consisting of the packet capture samples preprocessor and pre-trained binary classification model, we extract packet-level features and analyze protocol-specific anomalies, classifying the network traffic sample as malicious or normal activity. The study compares the performance of Random Forest, Naive Bayes, and a Neural Network. The Random Forest model, configured with 100 trees and a maximum depth of 5, demonstrates strong predictive capabilities. Naive Bayes leverages probabilistic classification, while the Neural Network, structured with two hidden layers and trained using the Adam optimizer, effectively captures complex traffic patterns. The study employs three classification models: Random Forest, Naive Bayes, and a Neural Network. The Random Forest classifier is configured with 100 trees and a maximum depth of 5. The Naive Bayes model utilizes Gaussian probability distributions for classification. The Neural Network consists of a multi-layer perceptron with two hidden layers of 40 and 20 neurons, using ReLU activation functions and trained with the Adam optimizer. Experimental results demonstrate the model's capability to identify protocol-specific threats with high accuracy, showcasing the potential of DPI-driven ML approaches for securing IIoT environments.</p>
<h1 id="44">Selected methods in N-body simulations</h1><h3>Aleksy Bałaziński</h3><p>This paper discusses the implementation of the particle-mesh (PM) and particle-particle particle-mesh (P3M) methods in the context of a spiral galaxy simulation. Simulations performed using both methods correctly predict the formation of characteristic spiral arms and demonstrate expected physical behavior, satisfying Newton’s second law and conserving energy and angular momentum. The PM code was written for both the CPU and GPU architectures, with the GPU version achieving approximately sevenfold speedup compared to the multithreaded CPU implementation.</p>
<h1 id="46">Performance Comparison of WebAssembly and  JavaScript</h1><h3>Jakub Ciszewski, Kaja Myk</h3><p>JavaScript remains the dominant language for client-side scripting, while WebAssembly offers near-native execution speeds, making it a compelling choice for computationally intensive tasks. This study provides a comprehensive analysis of the performance differences between WebAssembly and JavaScript across various computing environments, including different browsers (Firefox, Chrome, Edge) and platforms (desktop and mobile). To evaluate computational efficiency, we conducted a series of benchmark tests, including integer operations (Sieve of Eratosthenes, sorting algorithms), floating-point calculations (numerical integration, Monte Carlo method), and recursive computations (Fibonacci sequence, matrix multiplication). Additionally, we investigated the impact of WebAssembly on machine learning workloads by utilizing minimalist implementations such as TinyDNN for digit classification on the MNIST dataset. Our findings indicate that WebAssembly consistently outperforms JavaScript in CPU-bound tasks, particularly in integer operations and recursive computations. However, JavaScript’s just-in-time (JIT) compilation allows it to remain competitive in some floating-point calculations. One focus of our study was the application of WebAssembly in browser-based machine learning. We examined the performance of lightweight neural network implementations, emphasizing WebAssembly’s ability to accelerate tensor computations directly in the browser. This capability is crucial for deploying AI models on the client side, reducing reliance on cloud-based services, improving privacy, and minimizing latency. Our analysis also explores WebAssembly’s potential for real-time applications such as image classification, object detection, and natural language processing. Beyond raw performance metrics, this study assesses the broader implications of WebAssembly’s adoption in web development. One of its key advantages is its ability to support multiple   programming languages, including Rust, C, and C++, allowing developers to leverage high-performance libraries within the browser environment. Additionally, WebAssembly’s sandboxing mechanisms enhance security by isolating execution, reducing potential attack vectors compared to traditional JavaScript-based applications. Despite its advantages, WebAssembly has limitations. Execution performance varies across browsers, and its integration with JavaScript-based applications presents challenges due to data serialization overhead. Moreover, WebAssembly lacks direct access to the DOM, necessitating JavaScript as an intermediary for UI interactions. As WebAssembly continues to evolve, its role in performance critical web applications is expected to expand, particularly in fields such as cryptography, data processing, and real-time machine learning.</p>
<h1 id="49">Wpływ facylitacji na efektywność spotkań w projektach IT</h1><h3>Darya Vasilchyk</h3><p>Efektywna komunikacja między zespołami IT a biznesem jest jednym z kluczowych czynników sukcesu projektów. Jednak różnice w oczekiwaniach, niejasne wymagania oraz nieskuteczne spotkania często prowadzą do barier we współpracy. Niniejsza praca identyfikuje najistotniejsze wyzwania komunikacyjne oraz analizuje wpływ technik facylitacyjnych na usprawnienie współpracy w projektach IT, koncentrując się na studium przypadku startupu tworzącego mobilną grę do nauki języków. Badania obejmują ocenę, w jaki sposób strukturalne metody facylitacyjne wpływają na budowanie porozumienia między członkami zespołu projektowego. Analizowany przypadek przedstawia ewolucję uczestników, którzy w miarę wzrostu napotykali trudności komunikacyjne i sukcesywnie je eliminowali dzięki zastosowaniu facylitacji. Zdefiniowano główne bariery komunikacyjne, jak różnice priorytetów, brak jasności, pomijanie wypowiedzi i niedostateczne zaangażowanie. Najbardziej przydatnym metodami facylitacyjnymi okazały się Poza zakresem, Diagram Przepływu, Parafrazowanie oraz Agenda procesu. Otrzymane wyniki sugerują, że facylitacja jest wartościowym narzędziem w projektach IT, które może wspierać zespoły w skutecznym rozwiązywaniu konfliktów, budowaniu atmosfery współpracy i zwiększeniu produktywności spotkań.</p>
<h1 id="52">Low-cost, home-made Quantum Computer</h1><h3>Hubert Kołcz</h3><p>This presentation explores the development of a low-cost, home-built quantum computer aimed at validating hypotheses from numerical simulations, combining theoretical advancements in quantum computing with practical engineering solutions. Three configurations are discussed: an Intel Labs-inspired setup demonstrating pulse-level control programming with PennyLane and benchmarking using the Deutsch-Jozsa algorithm; a detailed guide to implementing the Deutsch-Jozsa algorithm at home, supported by foundational quantum information science principles; an approach to generating entanglement through nonlinear effects in Beta Barium Borate (BBO) crystals, leveraging Kerr effects. The project underscores the feasibility of constructing functional quantum systems outside specialized laboratories, and highlights the potential for democratizing access to quantum technologies.</p>
<h1 id="53">Database Index Costs in the Cloud-Based Multitenant Architecture on the Salesforce Platform</h1><h3>Stanislaw Zań</h3><p>Study on how in the multitenant cloud architecture of the Salesforce platform, different field configurations available to administrators impact database index usage, query costs, and data manipulation language operations. Results show that while "External ID" and "Unique" settings consistently create indexes with varying performance effects, the "Required" flag unexpectedly affects query costs in a meaningful manner. Results highlight the need for case-by-case tuning using the Salesforce Query Planner.</p>
<h1 id="55">A Survey of Consensus Algorithms in Distributed Ledger Technology for Internet of Things</h1><h3>Paweł Podgórski</h3><p>This comprehensive survey examines consensus algorithms utilized in Distributed Ledger Technology (DLT) for  Internet of Things (IoT) environments. The paper provides a  comparative analysis of consensus protocols including Proof of  Work, Proof of Stake, Proof of Authority, Proof of Elapsed Time,  Proof of Space, Proof of Activity, Practical Byzantine Fault Tolerance algorithm and Directed Acyclic Graph based approaches  such as Adaptive Proof of Work, and Temporal Proof. These  algorithms are evaluated against critical metrics for IoT contexts:  energy efficiency, transaction throughput, scalability, latency,  and security guarantees. The survey highlights fundamental  trade-offs between decentralization, security, and performance in DLT implementations, with particular focus on mechanisms  compatible with resource-constrained IoT networks. Through  this systematic comparison, the paper provides a comprehensive  overview of the suitability of various consensus mechanisms  within IoT-oriented distributed ledger systems.</p>
<h1 id="57">Comparison of the Performance and Effectiveness of Hashing Algorithms</h1><h3>Konrad Zilinski</h3><p>This study compares the performance and efficiency of various hashing algorithms with a focus on their collision resistance and computational speed. The study was conducted on a mobile platform, analyzing historical and modern implementations of hash functions such as MD5, SHA-1, SHA-2, SHA-3, and Blake in different variants. The paper discusses their applications, advantages, and disadvantages, as well as the impact of architecture on performance. The results of the tests made it possible to identify the algorithm that offers the optimal compromise between security and computational efficiency.</p>
</body></html>
